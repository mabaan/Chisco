<!-- Image & TITLE -->
<div align="center">
  <a href="https://github.com/mabaan/Imagined-Speech-EEG-Classification">
    <img src="https://github.com/user-attachments/assets/f6a738bf-42b4-4478-8fed-c39e2c8e895c" alt="Imagined Speech" width="300">
  </a>
  <h2 align="center">ğŸ§  Mind Reading AI: Arabic Word Classification from Brain Signals</h3>
</div>

## What This Project Does

Ever wondered if computers could read your mind? Well, this project gets pretty close! 

We've built an AI system that can figure out what Arabic words people are thinking about just by looking at their brain signals (EEG). When someone imagines saying a word like "Ù†Ø¹Ù…" (yes) or "Ù„Ø§" (no), their brain produces unique electrical patterns. Our AI learns to recognize these patterns and guess the word with impressive accuracy.

**The Amazing Results:** Our best model can correctly identify the imagined word **91.5%** of the time! That's like having a mind reader that's right 9 out of 10 times.

## How It Works (The Simple Version)

1. **ğŸ“Š Collect Brain Data:** People wear EEG headsets while imagining Arabic words
2. **ğŸ”§ Clean the Data:** We remove noise and organize the messy brain signals  
3. **ğŸ¤– Train the AI:** Our models learn the unique "fingerprint" of each thought
4. **ğŸ¯ Test & Predict:** The AI tries to guess new words it hasn't seen before

## The Tech Stack

- **Dataset:** ArEEG - Real brain recordings from people imagining 16 different Arabic words
- **Hardware:** 14-channel Emotiv Epoc X EEG headset (128 Hz sampling)
- **AI Models:** Advanced neural networks including EEGNet and Transformer ensembles
- **Magic Sauce:** Feature engineering with brain wave analysis + ensemble learning


## ğŸš€ Quick Start Guide

Want to train your own mind-reading AI? Here's how:

### 1. Set Up Your Environment
```bash
# Create a fresh Python environment (recommended)
pip install -r requirements.txt
```

### 2. Organize Your Data
Put your EEG data in this structure:
```
data/AREEG_Words/
â”œâ”€â”€ raw_csv/
â”‚   â”œâ”€â”€ Ù†Ø¹Ù…/          # Arabic word folders
â”‚   â”œâ”€â”€ Ù„Ø§/           # Each contains CSV files
â”‚   â””â”€â”€ ...
â”œâ”€â”€ labels.json       # Word â†’ number mapping
â””â”€â”€ channels_14.txt   # EEG channel names
```

### 3. Cook Your Data (Preprocessing)
```bash
# Transform messy CSVs into clean training data
python preprocessing.py --root data/AREEG_Words --overlap 0.75
```
This creates organized data files ready for AI training.

### 4. Train Your Mind Reader
```bash
# Train a basic model
python EEGclassify.py --head transformer --epochs 200

# Train an advanced ensemble model (recommended)
python EEGclassify.py --head transformer --ensemble 5 --epochs 1000
```

### 5. Watch the Magic Happen
The AI will start learning to read minds! You'll see accuracy improve over time:
```
Epoch 100: Validation Accuracy: 45.2%
Epoch 500: Validation Accuracy: 78.9%
Epoch 1000: Validation Accuracy: 91.5% ğŸ‰
```


## ğŸ§  How the Brain Data Works

### The Raw Signals
- **Source:** Real people wearing EEG headsets while imagining Arabic words
- **Hardware:** 14-channel Emotiv Epoc X (like a fancy brain-reading hat)
- **Sampling:** 128 measurements per second (128 Hz)
- **Duration:** 2-second clips of brain activity per thought

### The Cleaning Process (What `data_imagine.py` does)
Think of raw EEG like a noisy radio signal - lots of static mixed with the good stuff:

1. **Filter Out Noise:** Remove electrical interference and muscle movements
2. **Extract Features:** Calculate brain wave power in different frequency bands:
   - Delta (0.5-4 Hz): Deep sleep patterns
   - Theta (4-8 Hz): Drowsiness, creativity  
   - Alpha (8-13 Hz): Relaxed awareness
   - Beta (13-30 Hz): Active thinking
   - Gamma (30+ Hz): High-level cognitive processing
3. **Organize:** Cut long recordings into 2-second windows
4. **Standardize:** Make sure all signals are on the same scale

### The Final Product
- **Original:** 14 EEG channels measuring raw brain electricity
- **Enhanced:** +5 brain wave power features = 19 total channels
- **Shape:** [N samples, 19 channels, 256 time points]
- **Split:** 70% training, 15% validation, 15% testing


## ğŸ¤– The AI Models (Brain Decoders)

We've built several types of "mind readers," each with different superpowers:

### 1. EEGNet (The Classic)
- **What it is:** A proven neural network designed specifically for brain signals
- **How it works:** Looks for patterns in time and across brain regions
- **Strength:** Reliable and fast
- **Best for:** Getting started, baseline comparisons

### 2. EEGNet + Transformer (The Modern Approach)
- **What it is:** Combines classic EEG processing with attention mechanisms (like ChatGPT)
- **How it works:** "Pays attention" to the most important parts of brain signals
- **Strength:** Can capture complex temporal relationships
- **Best for:** Higher accuracy, state-of-the-art results

### 3. Ensemble Models (The Dream Team)
- **What it is:** Multiple AI models working together and voting on the answer
- **How it works:** Like having 5 experts instead of 1 - they discuss and agree
- **Strength:** Best possible accuracy through collective intelligence
- **Best for:** Maximum performance, research applications

### Training Features
- **Smart Learning:** Gradual warm-up, then intelligent scheduling
- **Data Augmentation:** Teaches the AI to handle variations in brain signals  
- **Class Balancing:** Makes sure the AI doesn't favor common words
- **Early Stopping:** Prevents overfitting (memorizing instead of learning)


## Training Procedure

Optimisation
- Optimizer: AdamW
- Learning rate: 3e-4 by default
- Weight decay: 1e-2 by default
- Learning rate schedule: linear warmup for the first warmup epochs then cosine decay to zero

Loss and regularisation
- Cross entropy with class weights inversely proportional to class counts in the training set
- Label smoothing of 0.05

Data augmentation
- Time shift: random circular shift in time of up to 8 samples which is about 62 ms at 128 Hz
- Mixup: convex combination of pairs in a batch with Beta alpha equal to 0.2

Metrics and logging
- Top 1 and Top 3 accuracy on validation and test sets
- Best validation model is saved to disk and reloaded for final test evaluation

Reproducibility
- NumPy and PyTorch seeds are set from the command line argument seed

Practical notes
- Adjust batch size based on GPU memory. 256 works on common 8 GB or 12 GB GPUs. Reduce if you see out of memory errors
- If your data has more than 14 channels or a different order, update channels_14.txt and rebuild the PKLs


## Expected Inputs and Outputs

Inputs to training
- Preprocessed PKLs with keys X, y, meta, channels, idx_to_label, sr, win_samples
- Shapes: X is [N, 14, T], y is [N]

Model I or O
- Input tensor: float32 EEG windows of shape [B, 14, T]
- Output tensor: logits of shape [B, n_classes]

Saved artifacts
- Model checkpoint file best_areeg_eegnet.pt
- Split indices at data/AREEG_Words/split/indices.pkl


## ğŸ† Amazing Results

Our AI has achieved mind-reading superpowers! Here's what we accomplished:

### The Best Performance
- **Top-1 Accuracy:** 91.5% (correctly guesses the exact word 9 out of 10 times!)
- **Top-3 Accuracy:** 96.5% (the correct word is in the top 3 guesses 96.5% of the time)
- **Dataset:** 16 different Arabic words from real brain recordings

### What This Means
Imagine if someone thought of the Arabic word "Ù†Ø¹Ù…" (yes):
- **91.5% of the time:** Our AI correctly says "This person is thinking 'Ù†Ø¹Ù…'"
- **96.5% of the time:** "Ù†Ø¹Ù…" is in the AI's top 3 guesses

This is **incredibly impressive** for brain-computer interfaces!

### Training Details
```bash
# The winning command that achieved these results:
python EEGclassify.py --head transformer --ensemble 5 --epochs 1200 \
  --lr 1e-3 --batch 32 --dropout 0.3 --weight_decay 5e-4
```

**What made it work:**
- ğŸ§  Ensemble of 5 transformer models working together
- ğŸ“Š Enhanced features: 14 EEG channels + 5 brain wave power bands
- ğŸ¯ Extended training: 1200 epochs with smart scheduling
- ğŸ›¡ï¸ Advanced regularization to prevent overfitting

### Comparison to Previous Work
- **Basic EEGNet:** ~60-70% accuracy
- **Our Enhanced Version:** 91.5% accuracy
- **Improvement:** +20-30% better than standard approaches!


## ğŸ“ Project File Guide

Here's what each file does (in human terms):

### ğŸ”§ Data Preparation
- **`data_imagine.py`** - The data chef that cleans and organizes raw brain signals
- **`preprocessing.py`** - Simple command-line tool to run the data preparation
- **`mapping.ipynb`** - Creates the word-to-number mapping for Arabic labels

### ğŸ¤– AI Models & Training  
- **`eegcnn.py`** - Contains the actual AI brain decoder models
- **`EEGclassify.py`** - The training gym where AI learns to read minds
- **`best_areeg_eegnet.pt`** - Saved AI model (your trained mind reader!)

### ğŸ“Š Analysis & Checking
- **`check_areeg.py`** - Checks if your data looks correct
- **`check_split.py`** - Verifies data splits are working properly

### ğŸ“š Documentation
- **`README.md`** - This file! Your complete guide
- **`requirements.txt`** - List of needed Python packages
- **`ArEEG.pdf`** - Original research paper about the dataset

### ğŸ’¾ Data Folders
- **`data/AREEG_Words/raw_csv/`** - Your original EEG CSV files
- **`data/AREEG_Words/preprocessed_pkl/`** - Clean, ready-to-use data
- **`data/AREEG_Words/split/`** - Information about train/test splits

Think of it like this:
1. ğŸ“¥ **Raw data goes into** `raw_csv/`
2. ğŸ”§ **Gets processed by** `data_imagine.py` 
3. ğŸ’¾ **Clean data comes out in** `preprocessed_pkl/`
4. ğŸ¤– **AI models train using** `EEGclassify.py`
5. ğŸ† **Best model gets saved as** `best_areeg_eegnet.pt`
  
## ğŸ™ Credits & Acknowledgments

**ğŸ‰ Huge thanks to the original researchers!** 

All credit for the ArEEG dataset and the amazing brain-computer interface research belongs to the brilliant scientists who collected this data. They did the hard work of recording real brain signals from people imagining Arabic words.

**Original Paper:** "ArEEG_Words: Dataset for Envisioned Speech Recognition using EEG for Arabic Words"  
**Research Link:** https://arxiv.org/pdf/2411.18888  
**Original Repository:** https://github.com/mabaan/Imagined-Speech-EEG-Classification

**What we built on top:** This repository adds advanced AI techniques like transformer ensembles, enhanced feature engineering, and modern training methods to push the accuracy even higher.

**The Science:** Brain-computer interfaces could revolutionize how we interact with technology - helping people with disabilities communicate, controlling devices with thoughts, and advancing our understanding of the human brain.

---

### ğŸš€ Ready to Train Your Mind Reader?

Clone this repository, follow the quick start guide, and soon you'll have your own AI that can peek into people's thoughts! ğŸ§ âœ¨

```bash
git clone https://github.com/your-repo/chisco
cd chisco
pip install -r requirements.txt
python preprocessing.py --root data/AREEG_Words
python EEGclassify.py --head transformer --ensemble 5
```

*Happy mind reading!* ğŸ”®
